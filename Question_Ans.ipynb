{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Content</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>['1', 'introduct', 'human', 'be', 'curiou', 't...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>['210th', 'standard', 'scienc', 'mechan', 'bra...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>['3', 'law', 'motion', '1', '4', 'newton', 's'...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>['410th', 'standard', 'scienc', 'if', 'result'...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>['5', 'law', 'motion', 'the', 'rod', 'turn', '...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            Content  Pages  Unit\n",
       "0           8  ['1', 'introduct', 'human', 'be', 'curiou', 't...      1     1\n",
       "1           9  ['210th', 'standard', 'scienc', 'mechan', 'bra...      2     1\n",
       "2          10  ['3', 'law', 'motion', '1', '4', 'newton', 's'...      3     1\n",
       "3          11  ['410th', 'standard', 'scienc', 'if', 'result'...      4     1\n",
       "4          12  ['5', 'law', 'motion', 'the', 'rod', 'turn', '...      5     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_data = pd.read_csv(\"Content.csv\",encoding = \"latin\")\n",
    "message_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data = message_data.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data = message_data.rename(columns = {'Content':'content','Unit':'unit'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Pages</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.50</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>4.760952</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.75</td>\n",
       "      <td>23.5</td>\n",
       "      <td>27.25</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>3.027650</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.25</td>\n",
       "      <td>36.5</td>\n",
       "      <td>38.75</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.049752</td>\n",
       "      <td>42.0</td>\n",
       "      <td>46.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>54.00</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>59.0</td>\n",
       "      <td>62.50</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.50</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5.049752</td>\n",
       "      <td>74.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>82.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.50</td>\n",
       "      <td>98.0</td>\n",
       "      <td>101.50</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.0</td>\n",
       "      <td>114.5</td>\n",
       "      <td>5.338539</td>\n",
       "      <td>106.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>114.5</td>\n",
       "      <td>118.75</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.894440</td>\n",
       "      <td>124.0</td>\n",
       "      <td>127.00</td>\n",
       "      <td>130.0</td>\n",
       "      <td>133.00</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18.0</td>\n",
       "      <td>145.5</td>\n",
       "      <td>5.338539</td>\n",
       "      <td>137.0</td>\n",
       "      <td>141.25</td>\n",
       "      <td>145.5</td>\n",
       "      <td>149.75</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18.0</td>\n",
       "      <td>163.5</td>\n",
       "      <td>5.338539</td>\n",
       "      <td>155.0</td>\n",
       "      <td>159.25</td>\n",
       "      <td>163.5</td>\n",
       "      <td>167.75</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.0</td>\n",
       "      <td>179.5</td>\n",
       "      <td>4.183300</td>\n",
       "      <td>173.0</td>\n",
       "      <td>176.25</td>\n",
       "      <td>179.5</td>\n",
       "      <td>182.75</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3.894440</td>\n",
       "      <td>187.0</td>\n",
       "      <td>190.00</td>\n",
       "      <td>193.0</td>\n",
       "      <td>196.00</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18.0</td>\n",
       "      <td>208.5</td>\n",
       "      <td>5.338539</td>\n",
       "      <td>200.0</td>\n",
       "      <td>204.25</td>\n",
       "      <td>208.5</td>\n",
       "      <td>212.75</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>218.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>223.0</td>\n",
       "      <td>225.50</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.0</td>\n",
       "      <td>235.5</td>\n",
       "      <td>4.183300</td>\n",
       "      <td>229.0</td>\n",
       "      <td>232.25</td>\n",
       "      <td>235.5</td>\n",
       "      <td>238.75</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>251.5</td>\n",
       "      <td>5.338539</td>\n",
       "      <td>243.0</td>\n",
       "      <td>247.25</td>\n",
       "      <td>251.5</td>\n",
       "      <td>255.75</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>3.894440</td>\n",
       "      <td>261.0</td>\n",
       "      <td>264.00</td>\n",
       "      <td>267.0</td>\n",
       "      <td>270.00</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12.0</td>\n",
       "      <td>279.5</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>274.0</td>\n",
       "      <td>276.75</td>\n",
       "      <td>279.5</td>\n",
       "      <td>282.25</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.0</td>\n",
       "      <td>292.5</td>\n",
       "      <td>4.183300</td>\n",
       "      <td>286.0</td>\n",
       "      <td>289.25</td>\n",
       "      <td>292.5</td>\n",
       "      <td>295.75</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>300.0</td>\n",
       "      <td>303.50</td>\n",
       "      <td>307.0</td>\n",
       "      <td>310.50</td>\n",
       "      <td>314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14.0</td>\n",
       "      <td>321.5</td>\n",
       "      <td>4.183300</td>\n",
       "      <td>315.0</td>\n",
       "      <td>318.25</td>\n",
       "      <td>321.5</td>\n",
       "      <td>324.75</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>1.581139</td>\n",
       "      <td>329.0</td>\n",
       "      <td>330.00</td>\n",
       "      <td>331.0</td>\n",
       "      <td>332.00</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pages                                                      \n",
       "     count   mean       std    min     25%    50%     75%    max\n",
       "unit                                                            \n",
       "1     15.0    8.0  4.472136    1.0    4.50    8.0   11.50   15.0\n",
       "2     16.0   23.5  4.760952   16.0   19.75   23.5   27.25   31.0\n",
       "3     10.0   36.5  3.027650   32.0   34.25   36.5   38.75   41.0\n",
       "4     17.0   50.0  5.049752   42.0   46.00   50.0   54.00   58.0\n",
       "5     15.0   66.0  4.472136   59.0   62.50   66.0   69.50   73.0\n",
       "6     17.0   82.0  5.049752   74.0   78.00   82.0   86.00   90.0\n",
       "7     15.0   98.0  4.472136   91.0   94.50   98.0  101.50  105.0\n",
       "8     18.0  114.5  5.338539  106.0  110.25  114.5  118.75  123.0\n",
       "9     13.0  130.0  3.894440  124.0  127.00  130.0  133.00  136.0\n",
       "10    18.0  145.5  5.338539  137.0  141.25  145.5  149.75  154.0\n",
       "11    18.0  163.5  5.338539  155.0  159.25  163.5  167.75  172.0\n",
       "12    14.0  179.5  4.183300  173.0  176.25  179.5  182.75  186.0\n",
       "13    13.0  193.0  3.894440  187.0  190.00  193.0  196.00  199.0\n",
       "14    18.0  208.5  5.338539  200.0  204.25  208.5  212.75  217.0\n",
       "15    11.0  223.0  3.316625  218.0  220.50  223.0  225.50  228.0\n",
       "16    14.0  235.5  4.183300  229.0  232.25  235.5  238.75  242.0\n",
       "17    18.0  251.5  5.338539  243.0  247.25  251.5  255.75  260.0\n",
       "18    13.0  267.0  3.894440  261.0  264.00  267.0  270.00  273.0\n",
       "19    12.0  279.5  3.605551  274.0  276.75  279.5  282.25  285.0\n",
       "20    14.0  292.5  4.183300  286.0  289.25  292.5  295.75  299.0\n",
       "21    15.0  307.0  4.472136  300.0  303.50  307.0  310.50  314.0\n",
       "22    14.0  321.5  4.183300  315.0  318.25  321.5  324.75  328.0\n",
       "23     5.0  331.0  1.581139  329.0  330.00  331.0  332.00  333.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_data.groupby('unit').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data_copy = message_data['content'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_preprocess(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data_copy = message_data_copy.apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1 introduct human curiou thing around thing ar...\n",
       "1      210th standard scienc mechan branch physic dea...\n",
       "2      3 law motion 1 4 newton law motion 1 4 1 newto...\n",
       "3      410th standard scienc result forc forc act bod...\n",
       "4      5 law motion rod turn fix point call point rot...\n",
       "5      610th standard scienc equilibrium algebra sum ...\n",
       "6      7 law motion unit forc amount forc requir prod...\n",
       "7      810th standard scienc fill fuel either liquid ...\n",
       "8      9 law motion let m1 m2 mass two bodi b place r...\n",
       "9      1010th standard scienc 1 10 5 variat acceler d...\n",
       "10     11 law motion tabl 1 2 appar weight person mov...\n",
       "11     1210th standard scienc 1 12 3 applic newton la...\n",
       "12     13 law motion choos correct answer 1 inertia b...\n",
       "13     1410th standard scienc iv match follow column ...\n",
       "14     15 law motion ix hot question 1 two block mass...\n",
       "15     1610th standard scienc introduct light form en...\n",
       "16     17 optic 6 differ colour light differ waveleng...\n",
       "17     1810th standard scienc 2 4 scatter light sunli...\n",
       "18     19 optic tyndal scatter beam sunlight enter du...\n",
       "19     2010th standard scienc 2 6 imag form due refra...\n",
       "20     21 optic figur 2 8 object place c object place...\n",
       "21     2210th standard scienc object anywher princip ...\n",
       "22     23 optic height object magnif denot letter hei...\n",
       "23     2410th standard scienc 2 16 human eye human ey...\n",
       "24     25 optic th e maximum distanc eye see object c...\n",
       "25     2610th standard scienc person may defect visio...\n",
       "26     27 optic side object len thi imag behav object...\n",
       "27     2810th standard scienc point rememb light form...\n",
       "28     29 optic choos correct answer 1 refract index ...\n",
       "29     3010th standard scienc 9 whi sky appear blue c...\n",
       "                             ...                        \n",
       "303    30410th standard scienc 21 4 tobacco abus toba...\n",
       "304    305 health diseas 21 5 alcohol abus consumpt a...\n",
       "305    30610th standard scienc increas blood glucos l...\n",
       "306    307 health diseas dietari manag low carbohydr ...\n",
       "307    30810th standard scienc caus risk factor obes ...\n",
       "308    309 health diseas 21 11 cancer cancer caus 4 m...\n",
       "309    31010th standard scienc 21 11 4 prevent measur...\n",
       "310    311 health diseas point rememb use certain dru...\n",
       "311    31210th standard scienc 8 metastasi associ mal...\n",
       "312    313 health diseas 2 chang lifestyl risk factor...\n",
       "313    31410th standard scienc concept map abus disor...\n",
       "314    315 introduct environment manag deal differ as...\n",
       "315    31610th standard scienc manag natur resourc te...\n",
       "316    317 environment manag 22 3 wildlif conserv wil...\n",
       "317    31810th standard scienc info bit wildlif conse...\n",
       "318    319 environment manag 22 5 2 coal petroleum co...\n",
       "319    32010th standard scienc solar cell solar cell ...\n",
       "320    321 environment manag 22 6 3 shale ga shale re...\n",
       "321    32210th standard scienc hydropow plant convert...\n",
       "322    323 environment manag overcom rapid deplet gro...\n",
       "323    32410th standard scienc caus sever soil ground...\n",
       "324    325 environment manag solid wast manag involv ...\n",
       "325    32610th standard scienc textbook evalu fill bl...\n",
       "326    327 environment manag c cultiv plant warm eart...\n",
       "327    32810th standard scienc refer book 1 ghatwal g...\n",
       "328    329329 introduct gener whenev think comput thi...\n",
       "329    33010th standard scienc 23 1 1 folder folder s...\n",
       "330    331331 visual commun languag develop massachus...\n",
       "331    33210th standard scienc ad sound 1 click sprit...\n",
       "332    333333 visual commun output choos best answer ...\n",
       "Name: content, Length: 333, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<333x7462 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 45110 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_mat = vectorizer.fit_transform(message_data_copy)\n",
    "message_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "message_train, message_test, unit_train, unit_test = train_test_split(message_mat, \n",
    "                                                        message_data['unit'], test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8059701492537313"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "unit_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "unit_model.fit(message_train, unit_train)\n",
    "pred = unit_model.predict(message_test)\n",
    "accuracy_score(unit_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stemmer (text):\n",
    "    text = text.split()\n",
    "    words = \"\"\n",
    "    for i in text:\n",
    "            stemmer = SnowballStemmer(\"english\")\n",
    "            words += (stemmer.stem(i))+\" \"\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "message_data_copy = message_data_copy.apply(stemmer)\n",
    "vectorizer = TfidfVectorizer(\"english\")\n",
    "message_mat = vectorizer.fit_transform(message_data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "message_train, message_test, unit_train, unit_test = train_test_split(message_mat, \n",
    "                                                        message_data['unit'], test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8059701492537313"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "unit_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "unit_model.fit(message_train, unit_train)\n",
    "pred = unit_model.predict(message_test)\n",
    "accuracy_score(unit_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>Pages</th>\n",
       "      <th>unit</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['1', 'introduct', 'human', 'be', 'curiou', 't...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['210th', 'standard', 'scienc', 'mechan', 'bra...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['3', 'law', 'motion', '1', '4', 'newton', 's'...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['410th', 'standard', 'scienc', 'if', 'result'...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['5', 'law', 'motion', 'the', 'rod', 'turn', '...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  Pages  unit  length\n",
       "0  ['1', 'introduct', 'human', 'be', 'curiou', 't...      1     1    2012\n",
       "1  ['210th', 'standard', 'scienc', 'mechan', 'bra...      2     1    2927\n",
       "2  ['3', 'law', 'motion', '1', '4', 'newton', 's'...      3     1    2686\n",
       "3  ['410th', 'standard', 'scienc', 'if', 'result'...      4     1    2024\n",
       "4  ['5', 'law', 'motion', 'the', 'rod', 'turn', '...      5     1    2755"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_data['length'] = message_data['content'].apply(len)\n",
    "message_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "length = message_data['length'].as_matrix()\n",
    "new_mat = np.hstack((message_mat.todense(),length[:, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8059701492537313"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "unit_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "unit_model.fit(message_train, unit_train)\n",
    "pred = unit_model.predict(message_test)\n",
    "accuracy_score(unit_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
